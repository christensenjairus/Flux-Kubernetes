apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata:
  name: homarr
  namespace: homarr
spec:
  interval: 30m
  chart:
    spec:
      chart: homarr
      version: "1.x.x"
      sourceRef:
        kind: HelmRepository
        name: homarr
        namespace: homarr
      interval: 12h
  values:


    # -- Default values for homarr
    # -- Declare variables to be passed into your templates.

    # -- Number of replicas
    replicaCount: 1

    image:
      # -- Image repository
      repository: ghcr.io/ajnart/homarr
      # -- Image pull policy
      pullPolicy: IfNotPresent
      # -- Overrides the image tag whose default is the chart appVersion
      tag: "0.15.3" # latest

    env:
      # -- Your local time zone
      TZ: "America/Denver"
      # -- Colors and preferences, possible values dark / light
      DEFAULT_COLOR_SCHEME: "dark"
      # -- Enabled authentication methods. Multiple providers can be enabled with by separating them with , (ex. AUTH_PROVIDER=credentials,oidc, it is highly recommended to just enable one provider).
      AUTH_PROVIDER: "credentials" #"ldap"

      # I couldn't get LDAP Auth to work. And I don't know why I'd want to if I just create the same public dash for everyone.

      # -- URI of your LDAP server
      AUTH_LDAP_URI: "ldap://openldap.openldap.svc:389"
      # -- Base dn of your LDAP server
      AUTH_LDAP_BASE: "dc=christensencloud,dc=us"
      # -- User used for finding users and groups
      AUTH_LDAP_BIND_DN: "cn=admin,dc=christensencloud,dc=us"
      # -- Attribute used for username
      AUTH_LDAP_USERNAME_ATTRIBUTE: "uid"
      # -- Class used for querying groups
      AUTH_LDAP_GROUP_CLASS: "groupOfNames" # default is groupOfUniqueNames
      # -- Attribute used for querying group member
      AUTH_LDAP_GROUP_MEMBER_ATTRIBUTE: "member"
      # -- User attribute used for comparing with group member
      AUTH_LDAP_GROUP_MEMBER_USER_ATTRIBUTE: "dn"
      # -- Admin group
      AUTH_LDAP_ADMIN_GROUP: "admin"
      # -- Owner group
      AUTH_LDAP_OWNER_GROUP: "admin"
      # -- LDAP search scope between base, one or sub
      AUTH_LDAP_SEARCH_SCOPE: "base" # default is base

      AUTH_LDAP_USERNAME_FILTER_EXTRA_ARG: '(objectClass=person)'
      AUTH_LDAP_GROUP_FILTER_EXTRA_ARG: '(|(objectclass=groupofNames)(objectclass=groupofUniqueNames))'


      # -- URI of OIDC provider
      AUTH_OIDC_URI:
      # -- Display name of provider (in login screen)
      AUTH_OIDC_CLIENT_NAME: "OIDC"
      # -- Admin group
      AUTH_OIDC_ADMIN_GROUP: "admin"
      # -- Owner group
      AUTH_OIDC_OWNER_GROUP: "admin"
      # -- Override the OIDC scopes
      AUTH_OIDC_SCOPE_OVERWRITE: "openid email profile groups"

    # Sensitive values that need to be passed in through environment variables should use kubernetes secrets. In order
    # to use this, create the secret in your target namespace before applying this helm chart. If you really want to,
    # you CAN just put these in the env block above, but that is not recommended.
    envSecrets:
      # -- ID of OIDC client (application)
      AUTH_OIDC_CLIENT_ID:
        key: # key name within the secret
        name: # name of the secret

      # -- Secret of OIDC client (application)
      AUTH_OIDC_CLIENT_SECRET:
        key: # key name within the secret
        name: # name of the secret

      # -- Password for bind user
#      AUTH_LDAP_BIND_PASSWORD:
#        key: password
#        name: ldap-admin-creds

    # -- Secrets for Docker registry
    imagePullSecrets: [ ]
    # -- Overrides chart's name
    nameOverride: ""
    # -- Overrides chart's fullname
    fullnameOverride: ""

    # -- Pod annotations
    podAnnotations: { }
    # -- Pod labels
    podLabels: { }

    # -- Pod security context
    podSecurityContext: { }
    # fsGroup: 2000

    # -- Security context
    securityContext: { }
    #   capabilities:
    #     drop:
    #     - ALL
    #   readOnlyRootFilesystem: true
    #   runAsNonRoot: true
    #   runAsUser: 1000

    # -- Service configuration
    service:
      # -- Service type
      type: ClusterIP
      # -- Service port
      port: 7575
      # -- Service target port
      targetPort: 7575

    # -- Ingress configuration
    ingress:
      # -- Enable ingress
      enabled: false
      # -- Ingress class name
      ingressClassName: "nginx-public"
      # -- Ingress annotations
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt
        nginx.ingress.kubernetes.io/ssl-redirect: "true"
        nginx.ingress.kubernetes.io/auth-method: 'GET'
        nginx.ingress.kubernetes.io/auth-url: 'http://authelia.authelia.svc.cluster.local:9091/api/authz/auth-request'
        nginx.ingress.kubernetes.io/auth-signin: 'https://auth.christensencloud.us?rm=$request_method'
        nginx.ingress.kubernetes.io/auth-response-headers: 'Remote-User,Remote-Name,Remote-Groups,Remote-Email'
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      # -- Ingress hosts configuration
      hosts:
        - host: homarr.christensencloud.us
          paths:
            - path: /
      # -- Ingress TLS configuration
      tls:
       - secretName: homarr-christensencloud.us-tls
         hosts:
           - homarr.christensencloud.us

    # -- Resource configuration
    resources: { }
      # We usually recommend not to specify default resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

    # -- Autoscaling configuration
    autoscaling:
      # -- Enable autoscaling
      enabled: false
      # -- Minimum replicas
      minReplicas: 1
      # -- Maximum replicas
      maxReplicas: 100
      # -- Target CPU utilization for autoscaling
      targetCPUUtilizationPercentage: 80
      # -- Target Memory utilization for autoscaling
      # targetMemoryUtilizationPercentage: 80
    # -- Additional volumes on the output Deployment definition.

    # -- Persistent storage configuration
    persistence:
      - name: homarr-config
        # -- Enable homarr-config persistent storage
        enabled: true
        # -- homarr-config storage class name
        storageClassName: "ceph-block-3"
        # -- homarr-config access mode
        accessMode: "ReadWriteOnce"
        # -- homarr-config storage size
        size: "50Mi"
        # -- homarr-config mount path inside the pod
        mountPath: "/app/data/configs"
      - name: homarr-database
        # -- Enable homarr-database persistent storage
        enabled: true
        # -- homarr-database storage class name
        storageClassName: "ceph-block-3"
        # -- homarr-database access mode
        accessMode: "ReadWriteOnce"
        # -- homarr-database storage size
        size: "50Mi"
        # -- homarr-database mount path inside the pod
        mountPath: "/data"
      - name: homarr-icons
        # -- Enable homarr-icons persistent storage
        enabled: true
        # -- homarr-icons storage class name
        storageClassName: "ceph-block-3"
        # -- homarr-icons access mode
        accessMode: "ReadWriteOnce"
        # -- homarr-icons storage size
        size: "50Mi"
        # -- homarr-icons mount path inside the pod
        mountPath: "/app/public/icons"

    # -- Node selectors for pod scheduling
    nodeSelector:
      nodeclass: general
    # -- Node tolerations for pod scheduling
    tolerations: [ ]
    # -- Node affinity for pod scheduling
    affinity: { }

